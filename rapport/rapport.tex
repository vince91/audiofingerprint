
\documentclass[12pt]{article}

\usepackage[francais]{babel}
\usepackage[latin1]{inputenc} 
\usepackage[T1]{fontenc}
\usepackage{graphicx}

\usepackage{subfig}
\usepackage{amsfonts}
\usepackage{mathtools}
\usepackage{float}
\usepackage{hyperref}
\usepackage{pict2e}
\usepackage{geometry}

% section break
\usepackage{titlesec}
\newcommand{\sectionbreak}{\clearpage}


% geometry
\geometry{top=2.5cm,bottom=3cm,left=2.5cm,right=2.5cm}

\renewcommand{\FrenchLabelItem}{\textbullet}

\title{Rapport de projet SI380: Empreinte acoustique}
\author{Maxime \bsc{Sirbu}, 
	\texttt{maxime.sirbu@telecom-paristech.fr}\\
	Vincent \bsc{Timofti}, \texttt{vincent.timofti@telecom-paristech.fr}\\
	Télécom Paristech,\\\\
	}
\date{\today}



\graphicspath{ {./images/} }
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}

\begin{document}


\maketitle


\section{Introduction}

L'empreinte acoustique -- ou \emph{audio fingerprint} -- désigne une représentation d'un signal
audio pouvant servir d'identifiant unique. Le critère d'identifiabilté est en général celui de
l'oreille humaine, \emph{ie} deux signaux considérés comme identiques à l'écoute doivent avoir une
empreinte acoustique similaire. Par conséquent le système de construction d'empreinte doit être
robuste aux petites déformations qui n'altèrent pas l'identifiabilité du signal. Déformation telles
que l'ajout de bruit, la réverbération, la distortion\dots

De plus, un système efficace sera aussi robuste aux décalage temporels, c'est à dire qu'il sera
capable d'identifier un extrait de signal, même si celui si n'est pas aligné temporelement avec le
signal utilisé pour l'apprentissage de l'empreinte.

Le sytème d'identification par empreinte doit aussi être rapide et capable d'identifier un extrait
parmi un très grand nombre de signaux. Ceci pose deux contraintes majeures pour notre système :
\begin{itemize}
	\item La base de donnée contenant les empreintes ne doit pas être de taille trop importante.
	\item Les empreintes doivent permettre de différencier deux signaux distincts avec sans
		nécessiter une trop grande complexité.
\end{itemize}

Nous présenterons deux système de création et d'identification d'empreintes. Ces deux méthodes
utilisent un même principe de fonctionnement basé sur une table de hachage et des clés. Seule la
méthode de calcul des clés diffèrent :  La méthode «classique» -- utilisée notamment par
l'application shazam -- basée sur le spectrogramme du signal, et une méthode basée sur une
décomposition parcimonieuse du signal avec l'algorithme \emph{matching pursuit}.

Nous avons choisi de programmer en langage Python, et nous utilisons SQLite pour stocker les empreintes acoustiques.

Le code est accessible à l'adresse suivante :
\url{https://github.com/vince91/audiofingerprint}

\section{Principe de base}
\label{sec:principe_base}

\subsection{Recherche du plus proche voisin}
On défini une collection $\chi = \{x_1,x_2,\dots,x_L\}$ de $L$ signaux audios et un requête $q$ (un
nouvel extrait appartenant ou non à la base). On cherche alors l'élément de $\chi$ le plus proche de
$q$, c'est à dire son \emph{plus proche voisin}. Le problème revient alors à déterminer une mesure
de \emph{proximité} $d(x,y)$ entre deux signaux $x$ et $y$ tel que l'expression suivante donne le
\emph{plus proche voisin} de $q$ : \[ \argmin_{x \in \chi} d(x,q) \]

Bien entendu, le calcul de la mesure de proximité doit être le moins complexe possible. Impossible
donc d'effecture $L$ comparaison entre $q$ et les éléments de la collection. D'autant plus qu'en
pratique $q$ ne sera qu'un extrait du signal audio correspondant.


\subsection{Indexation}

\subsubsection{Descripteurs locaux}
L'idée derrière les deux algorithmes que nous présentons ici est d'utiliser des descripteurs locaux
pour la création de l'empreinte acoustique d'un signal. Ces descripteurs séléctionnent une partie de
l'information temporel et fréquentielle censé être caractéristique du signal donné.

On utilise ainsi ces descripteurs pour les signaux de référence et la requête. La fusion des
résultats de recherche des descripteurs de la requête nous permet alors de retrouver le signal ayant
le plus de similitudes mais  aussi le décalage de la requête avec celui-ci

\subsubsection{Table de hachage}
\label{sec:table_hachage}
Pour pouvoir effectuer une comparaison efficace des descripteurs, il faut utiliser un méthode
d'indexation rapide. L'un des modèles les plus performants est celui de la table de hachage

Un table de hachage se base sur un fonctionnement par paire clé-valeur et sur une fonction de
hachage. Soit une paire clé-valeur $(c,v)$ dans un espace $\mathcal{C} \times \mathbb{V}$, une fonction
de hachage $h \,: \,\mathcal{C} \rightarrow \mathbb{H}$ associe à chaque clé un indice de localisation
dans la table. La localisation de la paire $(c,v)$ est alors déterminée par la valeur de $h(c)$ : il
n'est pas nécessaire de parcourir toute la table.

Dans les deux cas nous utiliserons alors ce système de table de hachage pour nos descripteurs
locaux. Chaque paire clé-valeur de la table sera construite comme le montre la figure~\ref{fig:ex_cles} : on sélectionne deux valeurs
temps-fréquence $(f_1,t_1)\, (f_2,t_2)$ par une méthode propre à chaque système, la clé est alors le
triplet \[ c = (f_1,f_2,\delta_t = t_1 - t_2)\]
La valeur enregistrée est le duet $(t_1,k)$ où $k \in [0,\dots,L-1]$ est l'indice du signal de référence.

\begin{figure}[htbp]
	\center
	\includegraphics[width=.7\textwidth]{exemple_cles_not}
	\caption{Construction des clés}
	\label{fig:ex_cles}
\end{figure}

Lors de la construction de la table, il est normal qu'une clé apparaisse plusieurs fois dans
différents signaux, voir dans le même signal. On stocke cependant bien chaque valeur associée à une
même clé.


\subsection{Recherche}

Pour effecuter une recherche de similarité pour une requêt $q$, on va calculer des descripteurs
locaux de la même manière que pour l'apprentissage de la base. Chaque clé $c_j$ calculée fait alors
l'objet d'une recherche dans la base et renvoie donc les couples $(t_j^l,k_j^l)$ associés à cette clé,
si celle ci existe. Connaissant le temps d'apparition $t_j$ de la clé, on peut en déduire le
décalage temporel de cette clé avec chaque occurence : $\tau_j^l =t_j^l - t_j$. Pour éviter d'être
trop précis quant au décalage, on quantifiera souvent $\tau_j^l$ par une valeur assez importante.

On pourrait alors établir le décompte du nombre de clé en commun entre la requête et chaque signal,
mais on traiterait alors chaque descripteur local indépendamment les uns des autres. Il est donc
plus intéressant de prendre en compte le décalage temporel.

On construit alors les histogrammes $\mathbf{H}_k(\tau) \, : \, \mathbb{Z} \rightarrow \mathbb{N}$
qui contienent pour chaque indice $k \in [0,\dots,L-1]$ le nombre de clés ayant un décalage $\tau$
comme montré en figure~\ref{fig:ex_hist}.


\begin{figure}[htbp]
	\center
	\includegraphics[width=.7\textwidth]{hist}
	\caption{Exemples d'histogrammes}
	\label{fig:ex_hist}
\end{figure}

Le \emph{plus proche voisin} est donc donné par :
\[
	k_q,\tau_q = \argmax_{k \in [0,\dots,L], \tau \in \mathbb{Z}} \mathbf{H}_k(\tau)
\]
où $\tau_q$ est le décalage de l'extrait avec son \emph{plus proche voisin}.



\section{Méthode Shazam}

\subsection{Spectrogramme}

Le signal audio duquel nous devons extraire l'empreinte acoustique est tout d'abord découpé en trame de 5 secondes. Pour chacune de ces trames, nous calculons son spectrogramme (en utilisant des fenêtres de 1024 échantillons et un recouvrement de 75\%).

\begin{figure}[htbp]
    \center
    \includegraphics[width=13cm]{shazam1.png}
    \caption{Passage dans le domaine temps-fréquence}
\end{figure}

\subsection{Extraction de pics d'intensité}

Le spectrogramme est découpé selon un quadrillage 10x10. Dans chaque case du quadrillage nous extrayons le point d'intensité maximale, qui définira un pic. Nous avons donc 100 pics d'itensité par trame de 5 secondes. Un pic est défini par sa position (sa fréquence et l'instant à laquel il apparaît) :

\begin{equation}
	p_i = (f_i, t_i)
\end{equation}

\begin{figure}[htbp]
    \center
    \includegraphics[width=13cm]{shazam2.png}
    \caption{Extraction des pics d'intensité pour une trame}
\end{figure}

\subsection{Couplage des pics}

Nous créons des couples à partir des pics d'intensité. Un couple constitue une clé, chaque clé est défini par la fréquence du premier pic, la fréquence du deuxième pic, et la différence des instants des deux pics :

\begin{equation}
\begin{split} 
	p_1 = (f_1, t_1), p_2 = (f_2, t_2) \\
	c_k = (f_1, f_2, \delta_t=t_2-t_1)
\end{split} 
\end{equation}

Pour constituer un couple les pics précedents doivent satisfaire 2 conditions :
\begin{itemize}
	\item $ t_2 > t_1 $
	\item la distance euclidiènne entre les 2 pics doit être inférieur à un certain seuil d (le nombre de clé que l'on prendra pour une trame dépendra de ce seuil)
\end{itemize}

Nous obtenons finalement une liste de clés pour chaque trame.

\begin{figure}[htbp]
    \center
    \includegraphics[width=13cm]{shazam3.png}
    \caption{Couplage des pics d'intensité}
\end{figure}

\subsection{Construction de la base de données}

Pour chaque musique de notre bibliothèque musicale (100 musiques), nous appliquons les méthodes précédentes et extrayons les clés, que nous enregistrons dans la base de données. Le processus est répété 5 fois, tout en faisant varier le seuil d (seuil de distance admissible entre les pics). Nous obtenons pour la méthode Shazam 5 base de données distinctes :
\vspace{0.4cm}

\begin{center}
\begin{tabular}{|c|c|c|}
\hline
   BDD n° & Nombre de clés par seconde & Poids (Megaoctets) \\
\hline
   1 & 22,6 & 23 \\
\hline
   2 & 39,6 & 40,4 \\
\hline
   3 & 59 & 60 \\
\hline
   4 & 81,6 & 83,1 \\
\hline
   5 & 100,2 & 102,8  \\
\hline
\end{tabular}
\end{center}
\vspace{0.4cm}

La construction d'une base de données pour 100 musique (et pour une durée totale de 8,1 heures de musique) prend entre 12 et 15 minutes.

\subsection{Efficacité de la méthode Shazam}

La première expérimentation consiste à prendre 3 extraits de durée variable  pour chaque musique de notre bibliothèque musicale et de les tester sur chaque base de données.

\begin{figure}[htbp]
    \center
    \includegraphics[width=13cm]{shazam4.png}
    \caption{Expérimentation de la méthode Shazam sur des extraits non modifiés}
    \label{test1shaz}
\end{figure}

On remarque (\ref{test1shaz}) que notre implémentation assure un taux de reconnaissance musicale supérieure à 99\% lorsque les extraits sont d'une durée supérieure à 2 secondes. Ce taux est de 100\% pour des extraits de 5 secondes. Les performances entre les différentes bases de données se valent, mais il est évident que plus le nombre de clés par seconde est grand, plus le taux de reconnaissance le sera aussi.
\vspace{0.4cm}

Pour la deuxième expérimentation la bibliothèque musicale est modifiée de la façon suivante : on ajoute à chaque musique du bruit blanc ($\sigma^2=0.005$), de la réverberation et un applique un passe-haut (fréquence de coupure : 500 Hz) de façon à obtenir un effet microphone. Ces modifications sont réalisées avec l'outil en ligne de commande SoX : 

\texttt{sox input\_file.wav ouput\_file.wav highpass 500 reverb whitenoise vol 0.005}

Nous effectuons ensuite des tests identifques à la première expérimentation mais sur la bibliothèque modifiée.

\begin{figure}[htbp]
    \center
    \includegraphics[width=13cm]{shazam5.png}
    \caption{Expérimentation de la méthode Shazam sur des extraits modifiés}
    \label{test2shaz}
\end{figure}

Cette fois-ci (\ref{test2shaz}), on assure un taux de reconnaissance de 100\% lorsque les extraits sont d'une durée supérieur à 10 secondes (sauf pour la base de donnée n°1).
\vspace{0.4cm}

De ces deux expérimentations nous pouvons choisir un nombre de clés par seconde satisfaisant pour la construction de la base de données. La base de données n°1 (22,6 clés/seconde) est exclue, car on remarque que sa courbe de taux de reconnaissance se démarque trop des autres. Les autres bases ont des performances semblables, et comme le poids de la base de données est important (il faut imaginer une application réelle avec une bibliothèque musicale comportant des millions de titres), on choisit la base la plus légère : la base n°2 (39,6 clés/seconde).
\vspace{0.4cm}

En conclusion, le valeur de \textbf{40 clés par seconde} semble être un bon compromis pour la construction d'une base de donnée avec la méthode Shazam





\section{Méthode \emph{Matching Pursuit}}

La seconde méthode de calcul des clés est basé sur l'algorithme de décomposition
parcimonieuse \emph{matching pursuit} ou \bsc{mp}. Cet algorithme va nous permettre d'ajouter une
information sur les tailles des atomes qui sont ici nos descripteurs locaux, en plus de
l'information fréquentielle et temporelle.

\subsection{Formulation mathématiques}
Soit un espace de Hilbert $\mathcal H$, un dicionnaire d'éléments $d_\gamma \in \mathcal H$ et un
élément $x \in \mathcal H$, l'algorithme \bsc{mp} va construire une approximation de $x$ : $\tilde x_n =
\sum_{i=1}^{n}\alpha_i d_{\gamma^i}$ après $n$ itérations.

L'algorithme est un algorithme itératif en deux étapes. Initialement on défini le \textbf{résiduel}
$R^0x = x$, l'ensemble des éléments du dictionnaire sélectionnés $\Gamma^0 = \emptyset$. Lors de la
$n^{\text{ième}}$ itération, on procède alors comme suivant :
\begin{itemize}
	\item Sélection : on sélectionne un élement du dictionnaire $d_{\gamma^n}$ selon un critère
		de $\mathcal C$.
	\item Mise à jour : on met à jour l'approximation selon une règle $\mathcal A$ et on recalcule
		le résiduel.
\end{itemize}
La figure~\ref{fig:mp} décrit le fonctionnement de cet algorithme.

\begin{figure}[htbp]
	\centering
	\input{images/algomp}
	\caption{L'algorithme \bsc{mp}}
	\label{fig:mp}
\end{figure}

\subsection{Implémentation}

Pour notre implémentation, nous choisissons un dictionnaire redondant constitué d'une union de
bases \bsc{mdct} (\emph{Modified Discrete Cosine Transform}). La \bsc{mdct} est une transformée
basée sur la tranfromée en consinys discrete.

Pour un vecteur $x$ de taille $N=PK$ (\emph{ie} $x$ est composé de $P$ segments de taille $K$). La
\bsc{mdct} de taille $L = 2K$ s'écrit comme une matrice de transformation $\mathbf{T}$ de taille $N
\times N$ :
\[
	\mathbf{T}[n,pK+k] = \phi_{p,k}[n]\; \text{pour}\; p \in [0\dots P-1], k \in [0\dots K-1]
	\;\text{et}\; n \in [0\dots N-1]
\]
où :
\[
	\phi_{p,n}[n] = w_p[u] \sqrt{\frac 2K} \cos \left[\frac \pi K \left( u + \frac{K+1}2 \right)
		\left( k+\frac 12 \right) \right]
\]
avec $u = n-(p-\frac 12)K$ et $w_p$ une fenêtre d'analyse de la trame $p$. La condition d'inversion
qui permet une reconstruction parfaite se comprend alors comme une condition d'orthogonalité sur
$\mathbf{T}$ :
\[
	\mathbf{T}\mathbf{T}^T = \mathbf{I}
\]
on peut alors montrer que cette condition est vérifiée lorsque le fenêtre vérifie pour  $u \in
[0\dots K-1]$:
\begin{align}
	\label{eq:win_1}	w_0[u] & = 1 \\
	\label{eq:win_2}	w_p^2[u+\frac L2] + w^2_{p+1}[u] & =  1,p \in [0\dots P-2]\\
	\label{eq:win_3}	w_{P-1}[u+\frac L2] & = 1
\end{align}

Les conditions~\ref{eq:win_1} et~\ref{eq:win_3} assurent la conservation aux bords du signal.
La fenêtre que nous utilisons pour le mathcalcul de \bsc{mdct} est définie par :
\[
	w[u] = \sin\left[\frac\pi L \left( u + \frac 12 \right)\right]
\]
et vérifie bien la condition~\ref{eq:win_2}.

Notre dictionnaire est donc constitué d'atomes similaires à la figure~\ref{fig:atom}.
\begin{figure}[htbp]
	\centering
	\includegraphics[width=.3\textwidth]{atom}
	\caption{Atome d'une union de base mdct}
	\label{fig:atom}
\end{figure}
En utilisant un dicitonnaire d'union de bases \bsc{mdct} avec différentes tailles de fênetres, on
peut alors utiliser des atomes de tailles différentes pour être plus précis dans notre algorithme
\bsc{mp}.


Le critère $\mathcal C$ sélectionne donc l'atome ayant la plus grande valeur dans le résultat de
l'algorithme, et la mise à jour se fait en calculant la \bsc{mdct} inverse des atomes sélectionnés.
La figure~\ref{fig:mp_ex}  montre un exemple d'application de l'algorithme \bsc{mp}.


\begin{figure}[htbp]
	\centering
	\subfloat[]{\label{fig:mp_signal}\includegraphics[width=.5\textwidth]{mp_init}}
	\subfloat[]{\label{fig:mp_rec}\includegraphics[width=.5\textwidth]{mp_rec}}\\
	\subfloat[]{\label{fig:mp_signal}\includegraphics[width=.6\textwidth]{mp_result}}
	\caption{Exemple d'application de l'algorithme \bsc{mp} : \ref{fig:mp_signal} forme d'onde du
	signal d'origine. \ref{fig:mp_rec} signal reconstruit après 1000 itérations.
	\ref{fig:mp_signal}  visualisation de résultat dans le plan temps-fréquence.}
	\label{fig:mp_ex}
\end{figure}





\subsection{Améliorations}
Afin de réduire la complexité de l'algorithme \bsc{mp} et d'augmenter son efficacité, nous avons
effectuer de légères modification dans le déroulement de l'algorithme.

\subsubsection{Sélection}
À chaque itération, il est nécessaire de calculer la tranformée \bsc{mdct} du résiduel lors de
l'étape de sélection. Ceci peut devenir coûteux en temps de calcul si l'on a un grand nombre
d'itérations.

Cependant il n'est pas nécessaire de calculer la tranformée pour tout le signal, en effet seul la
partie temporel correspondant à l'atome sélectionné est affectée par la mise à jour. Il n'est donc
pas nécessaire de recalculer la transformée correspondant aux atomes qui ne sont pas correlés avec
l'atome sélectionné.

On modifie donc la fonction de calcul de \bsc{mdct}, pour ne mettre à jour que la partie du signal
où les atomes pourrait être affecté par le changement de résiduel.


\subsubsection{Masque}
L'algorithme \bsc{mp} à tendance à sélectionner les atomes la où il y a beacoup d'énergie, ils sont
donc en général proches fréquentiellement et temporellement.

L'idée est donc de changement le critère de sélection en utilsant un masque :
\[
	\mathcal{C_M}(R^nx,\mathcal D) = \argmax_{d_i \in \mathcal D}(|\langle
	R^nx,d_i \rangle|\mathcal M(d_i|\Gamma^n))
\]
où $\mathcal{M}(d_i|\Gamma^n)$ est un masque temps-fréquence construit à partir du support de
l'approximation courante $\Gamma^n$. On cherchera en donc à exprimer $\mathcal{M}$ de tel sorte que
la sélection d'un atome dans le voisinage temps-fréquence d'un atome déjà sélectionné soit fortement
pénalisé voire interdite.  On peut donc utiliser l'une des mesures suivantes:
\begin{align}
	\label{eq:mask1} \mathcal M(d_i|\Gamma^n) & = 1 - \max_{\gamma \in \Gamma^n} |\langle
	d_i,d_\gamma \rangle|\\
	\label{eq:mask2}\mathcal M(d_i|\Gamma^n) & = \left\{ \begin{array}{cl}
			0  & \text{si}\; \exists \gamma \in \Gamma^n, |\langle d_i,d_\gamma \rangle|
			\neq 0\\
			1 & \text{sinon}
		\end{array}
		\right.
\end{align}
Bien entendu, le masque défini par~\ref{eq:mask2} est bien plus restrictif que celui défini
par~\ref{eq:mask1}.




\subsection{Construction des clés}

Dans cette deuxième méthode nous utilsons donc l'algorithme \emph{Matching Pursuit} pour construire
nos clés.  On découpe notre signal d'entrée en trames de 5 secondes, puis on extrait les un nombre
$n$ d'atomes en utilisant l'algorithme \bsc{mp} avec un dictionnaire composé de trois tailles
d'atome différentes (128,1024 et 8192 échantillons).  On va ensuite apairer chaque atomes avec $p$
de ses plus proches voisins dans le plan temps-fréquence, en ne considérant que ceux
apparaisant après l'atome choisi. La figure \label{fig:mp_pairs} montre un exemple d'apairage avec
$p=1$.
\begin{figure}[htbp]
	\centering
	\includegraphics[width=.8\textwidth]{matching_pursuit_pairs}
	\caption{Sélection des paires d'atomes pour $p=1$}
	\label{fig:mp_pairs}
\end{figure}

On peut ensuite construire les clés qui constitueront notre base comme décrit dans la
section~\ref{sec:table_hachage}. On utilise en plus l'information d'échelle des atomes de la
paire pour construire notre clé, qui devient donc le quintuplet	:
\[
	c = (f_1,e_1,f_2,e_2,\delta_t = t_1 -t_2)
\]
Le reste du processus est le même que le principe de base décrit en section~\ref{sec:principe_base},
commun aux deux méthodes.


\subsection{Performances}


\clearpage
\tableofcontents
\end{document}

